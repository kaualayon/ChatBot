{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q llama-index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q llama-index-embeddings-huggingface\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q llama-index-vector-stores-chroma\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q  chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q llama-index-llms-groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q PyPDF2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import gradio as gr\n",
    "from typing import List\n",
    "from llama_index.core import SimpleDirectoryReader, StorageContext, VectorStoreIndex\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "from llama_index.llms.groq import Groq\n",
    "from llama_index.core.memory import ChatSummaryMemoryBuffer\n",
    "import chromadb\n",
    "from tempfile import TemporaryDirectory\n",
    "from PyPDF2 import PdfReader\n",
    "\n",
    "# Wrapper de embedding compatÃ­vel com ChromaDB\n",
    "class ChromaEmbeddingWrapper:\n",
    "    def __init__(self, model_name: str):\n",
    "        self.model = HuggingFaceEmbedding(model_name=model_name)\n",
    "\n",
    "    def __call__(self, input: List[str]) -> List[List[float]]:\n",
    "        return self.model.embed_documents(input)\n",
    "\n",
    "# Inicializa modelos de embedding\n",
    "embed_model = HuggingFaceEmbedding(model_name='intfloat/multilingual-e5-large')\n",
    "embed_model_chroma = ChromaEmbeddingWrapper(model_name='intfloat/multilingual-e5-large')\n",
    "\n",
    "# Inicializa ChromaDB\n",
    "chroma_client = chromadb.PersistentClient(path='./chroma_db')\n",
    "collection_name = 'documentos_doc_info_agricultura'\n",
    "chroma_collection = chroma_client.get_or_create_collection(\n",
    "    name=collection_name,\n",
    "    embedding_function=embed_model_chroma\n",
    ")\n",
    "\n",
    "vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "\n",
    "# Inicializa LLM da Groq\n",
    "Groq_api = os.environ.get(\"GROQ_API_KEY\")\n",
    "llms = Groq(model='llama3-70b-8192', api_key='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')\n",
    "\n",
    "# Estados globais\n",
    "document_index = None\n",
    "chat_engine = None\n",
    "\n",
    "# Processamento do PDF\n",
    "\n",
    "def process_pdf(file):\n",
    "    global document_index, chat_engine\n",
    "\n",
    "    try:\n",
    "        with TemporaryDirectory() as tmpdir:\n",
    "            pdf_path = os.path.join(tmpdir, \"upload.pdf\")\n",
    "            shutil.copy(file.name, pdf_path)\n",
    "\n",
    "            text = \"\"\n",
    "            reader = PdfReader(pdf_path)\n",
    "            for page in reader.pages:\n",
    "                text += page.extract_text() or \"\"\n",
    "\n",
    "            with open(os.path.join(tmpdir, \"temp.txt\"), \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(text)\n",
    "\n",
    "            documentos = SimpleDirectoryReader(input_dir=tmpdir)\n",
    "            docs = documentos.load_data()\n",
    "\n",
    "            node_parser = SentenceSplitter(chunk_size=1200)\n",
    "            nodes = node_parser.get_nodes_from_documents(docs, show_progress=True)\n",
    "\n",
    "            document_index = VectorStoreIndex(nodes, storage_context=storage_context, embed_model=embed_model)\n",
    "\n",
    "            memory = ChatSummaryMemoryBuffer(llm=llms, token_limit=256)\n",
    "\n",
    "            chat_engine = document_index.as_chat_engine(\n",
    "                chat_mode='context',\n",
    "                llm=llms,\n",
    "                memory=memory,\n",
    "                system_prompt='''Voce Ã© especialista agricultura, sua funÃ§ao Ã© tirar duvidas de forma simpatica e natural sobre informaÃ§oes relacionadas\n",
    "                a agricultura, tipos de solo, que auxilie o agricultor na escolha da semente e como preparar o solo para o plantio,  \n",
    "                bem como definir os limites de temperatura para o solo e irrigaÃ§Ã£o de acordo com a semente plantada.'''\n",
    "            )\n",
    "\n",
    "            return \"PDF carregado com sucesso! Agora vocÃª pode conversar com o bot.\"\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"Erro ao processar PDF: {e}\"\n",
    "\n",
    "# Chat com histÃ³rico estilo \"messages\"\n",
    "def converse_com_bot(message, chat_history):\n",
    "    global chat_engine\n",
    "\n",
    "    if chat_engine is None:\n",
    "        return \"Por favor, envie um PDF primeiro.\", chat_history\n",
    "\n",
    "    response = chat_engine.chat(message)\n",
    "\n",
    "    if chat_history is None:\n",
    "        chat_history = []\n",
    "\n",
    "    chat_history.append({\"role\": \"user\", \"content\": message})\n",
    "    chat_history.append({\"role\": \"assistant\", \"content\": response.response})\n",
    "\n",
    "    return \"\", chat_history\n",
    "\n",
    "# Resetar conversa\n",
    "def resetar_chat():\n",
    "    global chat_engine\n",
    "    if chat_engine:\n",
    "        chat_engine.reset()\n",
    "    return []\n",
    "\n",
    "# Interface Gradio com upload de PDF\n",
    "with gr.Blocks() as app:\n",
    "    gr.Markdown(\"# Chatbot Agricultura- Especialista em agricultura\")\n",
    "\n",
    "    with gr.Row():\n",
    "        upload = gr.File(label=\"ðŸ“„ Envie seu PDF\")\n",
    "        upload_button = gr.Button(\"Carregar PDF\")\n",
    "\n",
    "    output_status = gr.Textbox(label=\"Status\", interactive=False)\n",
    "\n",
    "    chatbot = gr.Chatbot(label=\"Conversa\", type=\"messages\")\n",
    "    msg = gr.Textbox(label='Digite a sua mensagem')\n",
    "    limpar = gr.Button('Limpar')\n",
    "\n",
    "    upload_button.click(process_pdf, inputs=upload, outputs=output_status).then(\n",
    "        resetar_chat, None, chatbot\n",
    "    )\n",
    "    msg.submit(converse_com_bot, [msg, chatbot], [msg, chatbot])\n",
    "    limpar.click(resetar_chat, None, chatbot, queue=False)\n",
    "\n",
    "    app.launch(debug=True)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
